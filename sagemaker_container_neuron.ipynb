{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba14f275-7f22-407e-9c5f-08bfb55a0ef7",
   "metadata": {},
   "source": [
    "# Deploy a pretrained PyTorch BERT model from HuggingFace on Amazon SageMaker with Neuron container with custom installations and inference.py script. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39838",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa860b-46f2-4038-b669-7adc72d3aa4f",
   "metadata": {},
   "source": [
    "This follows the documentation on [PyTorch BERT model](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/byoc_sm_bert_tutorial/sagemaker_container_neuron.html). Although the inference and code looks the same there has been considerable changes made on the docker file to adapt to the current env variables and also the dependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37445ad2",
   "metadata": {},
   "source": [
    "## Install Dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd765f",
   "metadata": {},
   "source": [
    "This tutorial requires the following pip packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3092c",
   "metadata": {},
   "source": [
    "- torch-neuron\n",
    "- neuron-cc[tensorflow]\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea285500-e322-4521-8f72-b1bb4f534f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c3731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=True #Supresses tokenizer warnings making errors easier to detect\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=True #Supresses tokenizer warnings making errors easier to detect\n",
    "!pip install --upgrade -q --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "!pip install --upgrade -q --no-cache-dir transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4796d3a",
   "metadata": {},
   "source": [
    "## Compile the model into an AWS Neuron optimized TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe85f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuron\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5c253a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ef795e480f45bb8641f4ac7361a994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54df7e2c7ea1494581f23d92cdebbd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e40205825254fb0be11c7faf9b06037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df0bb650084816937a9ef39cc849a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381ce8873a7f4ebfb4f80246f91521f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\", return_dict=False)\n",
    "\n",
    "# Setup some example inputs\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "max_length=128\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Run the original PyTorch model on compilation exaple\n",
    "paraphrase_classification_logits = model(**paraphrase)[0]\n",
    "\n",
    "# Convert example inputs to a format that is compatible with TorchScript tracing\n",
    "example_inputs_paraphrase = paraphrase['input_ids'], paraphrase['attention_mask'], paraphrase['token_type_ids']\n",
    "example_inputs_not_paraphrase = not_paraphrase['input_ids'], not_paraphrase['attention_mask'], not_paraphrase['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44255ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:There are 3 ops of 1 different types in the TorchScript that are not compiled by neuron-cc: aten::embedding, (For more information see https://awsdocs-neuron.readthedocs-hosted.com/en/latest/release-notes/compiler/neuron-cc/neuron-cc-ops/neuron-cc-ops-pytorch.html)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 565, fused = 548, percent fused = 96.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/ops/aten.py:2413: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$695 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]} --verbose 1'\n",
      "09/26/2023 05:07:39 PM INFO 20697 [root]: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]}' --verbose 1\n",
      "09/26/2023 05:07:39 PM INFO 20697 [root]: Intermediate files stored in /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60, output in /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60\n",
      "09/26/2023 05:07:39 PM INFO 20697 [pipeline.custom.0]: Running pipeline custom.0\n",
      "09/26/2023 05:07:39 PM INFO 20697 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "09/26/2023 05:07:39 PM INFO 20697 [pipeline.compile.0]: Running pipeline compile.0\n",
      "09/26/2023 05:07:39 PM INFO 20697 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "09/26/2023 05:07:39 PM INFO 20697 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]}'\n",
      "09/26/2023 05:07:45 PM INFO 20697 [job.Frontend.4]: IR signature: fd46a25ca88e6bb2f0ed7d9025c684c76c33e5e7191ed56bbc048c5b9ad9a6f0 for graph_def.pb\n",
      "09/26/2023 05:07:45 PM INFO 20697 [job.Frontend.4]: total padded opcount is 22348434432\n",
      "09/26/2023 05:07:45 PM INFO 20697 [job.Frontend.4]: Finished Jellyfish import\n",
      "09/26/2023 05:07:45 PM INFO 20697 [job.Frontend.4]: Start tensorization\n",
      "[17:07:54] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.17.2.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[17:07:54] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.17.2.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=11174217216\n",
      "Coloring: Total const bytes per part=1338326\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[17:07:54] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.17.2.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 11,174,217,216. Average number of cycles per partition: 11,174,217,216\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0  11,174,217,216 1,338,326           0         0         2         903\n",
      "Coloring: Total nubmer of cycles = 11,174,217,216\n",
      "Coloring: Largest number of cycles in part = 11,174,217,216, Ratio worst/best avg = 1\n",
      "\n",
      "\n",
      "\n",
      "[17:07:54] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.17.2.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/GELUActivation_3/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/GELUActivation_3/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/GELUActivation_3/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/GELUActivation_3/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/GELUActivation_3/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/Linear_2/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Linear_10/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Linear_10/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Tanh_11/aten_tanh/Tanh:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/aten_select/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/aten_select/Slice:0\n",
      "     tonga0:tpb0  Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  Linear_5/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  add0:0\n",
      "     tonga0:tpb0  copy10:0\n",
      "     tonga0:tpb0  copy11:0\n",
      "     tonga0:tpb0  copy12:0\n",
      "     tonga0:tpb0  copy13:0\n",
      "     tonga0:tpb0  copy14:0\n",
      "     tonga0:tpb0  copy15:0\n",
      "     tonga0:tpb0  copy16:0\n",
      "     tonga0:tpb0  copy17:0\n",
      "     tonga0:tpb0  copy18:0\n",
      "     tonga0:tpb0  copy19:0\n",
      "     tonga0:tpb0  copy20:0\n",
      "     tonga0:tpb0  copy6:0\n",
      "     tonga0:tpb0  copy7:0\n",
      "     tonga0:tpb0  copy8:0\n",
      "     tonga0:tpb0  copy9:0\n",
      "     tonga0:tpb0  nn.batch_matmul0:0\n",
      "     tonga0:tpb0  nn.batch_matmul10:0\n",
      "     tonga0:tpb0  nn.batch_matmul11:0\n",
      "     tonga0:tpb0  nn.batch_matmul12:0\n",
      "     tonga0:tpb0  nn.batch_matmul13:0\n",
      "     tonga0:tpb0  nn.batch_matmul14:0\n",
      "     tonga0:tpb0  nn.batch_matmul15:0\n",
      "     tonga0:tpb0  nn.batch_matmul16:0\n",
      "     tonga0:tpb0  nn.batch_matmul17:0\n",
      "     tonga0:tpb0  nn.batch_matmul18:0\n",
      "     tonga0:tpb0  nn.batch_matmul19:0\n",
      "     tonga0:tpb0  nn.batch_matmul1:0\n",
      "     tonga0:tpb0  nn.batch_matmul20:0\n",
      "     tonga0:tpb0  nn.batch_matmul21:0\n",
      "     tonga0:tpb0  nn.batch_matmul22:0\n",
      "     tonga0:tpb0  nn.batch_matmul23:0\n",
      "     tonga0:tpb0  nn.batch_matmul24:0\n",
      "     tonga0:tpb0  nn.batch_matmul25:0\n",
      "     tonga0:tpb0  nn.batch_matmul26:0\n",
      "     tonga0:tpb0  nn.batch_matmul27:0\n",
      "     tonga0:tpb0  nn.batch_matmul28:0\n",
      "     tonga0:tpb0  nn.batch_matmul29:0\n",
      "     tonga0:tpb0  nn.batch_matmul2:0\n",
      "     tonga0:tpb0  nn.batch_matmul30:0\n",
      "     tonga0:tpb0  nn.batch_matmul31:0\n",
      "     tonga0:tpb0  nn.batch_matmul32:0\n",
      "     tonga0:tpb0  nn.batch_matmul33:0\n",
      "     tonga0:tpb0  nn.batch_matmul34:0\n",
      "     tonga0:tpb0  nn.batch_matmul35:0\n",
      "     tonga0:tpb0  nn.batch_matmul36:0\n",
      "     tonga0:tpb0  nn.batch_matmul37:0\n",
      "     tonga0:tpb0  nn.batch_matmul38:0\n",
      "     tonga0:tpb0  nn.batch_matmul39:0\n",
      "     tonga0:tpb0  nn.batch_matmul3:0\n",
      "     tonga0:tpb0  nn.batch_matmul40:0\n",
      "     tonga0:tpb0  nn.batch_matmul41:0\n",
      "     tonga0:tpb0  nn.batch_matmul42:0\n",
      "     tonga0:tpb0  nn.batch_matmul43:0\n",
      "     tonga0:tpb0  nn.batch_matmul44:0\n",
      "     tonga0:tpb0  nn.batch_matmul45:0\n",
      "     tonga0:tpb0  nn.batch_matmul46:0\n",
      "     tonga0:tpb0  nn.batch_matmul47:0\n",
      "     tonga0:tpb0  nn.batch_matmul48:0\n",
      "     tonga0:tpb0  nn.batch_matmul49:0\n",
      "     tonga0:tpb0  nn.batch_matmul4:0\n",
      "     tonga0:tpb0  nn.batch_matmul50:0\n",
      "     tonga0:tpb0  nn.batch_matmul51:0\n",
      "     tonga0:tpb0  nn.batch_matmul52:0\n",
      "     tonga0:tpb0  nn.batch_matmul53:0\n",
      "     tonga0:tpb0  nn.batch_matmul54:0\n",
      "     tonga0:tpb0  nn.batch_matmul55:0\n",
      "     tonga0:tpb0  nn.batch_matmul56:0\n",
      "     tonga0:tpb0  nn.batch_matmul57:0\n",
      "     tonga0:tpb0  nn.batch_matmul58:0\n",
      "     tonga0:tpb0  nn.batch_matmul59:0\n",
      "     tonga0:tpb0  nn.batch_matmul5:0\n",
      "     tonga0:tpb0  nn.batch_matmul60:0\n",
      "     tonga0:tpb0  nn.batch_matmul61:0\n",
      "     tonga0:tpb0  nn.batch_matmul62:0\n",
      "     tonga0:tpb0  nn.batch_matmul63:0\n",
      "     tonga0:tpb0  nn.batch_matmul64:0\n",
      "     tonga0:tpb0  nn.batch_matmul65:0\n",
      "     tonga0:tpb0  nn.batch_matmul66:0\n",
      "     tonga0:tpb0  nn.batch_matmul67:0\n",
      "     tonga0:tpb0  nn.batch_matmul68:0\n",
      "     tonga0:tpb0  nn.batch_matmul69:0\n",
      "     tonga0:tpb0  nn.batch_matmul6:0\n",
      "     tonga0:tpb0  nn.batch_matmul70:0\n",
      "     tonga0:tpb0  nn.batch_matmul71:0\n",
      "     tonga0:tpb0  nn.batch_matmul72:0\n",
      "     tonga0:tpb0  nn.batch_matmul73:0\n",
      "     tonga0:tpb0  nn.batch_matmul74:0\n",
      "     tonga0:tpb0  nn.batch_matmul75:0\n",
      "     tonga0:tpb0  nn.batch_matmul76:0\n",
      "     tonga0:tpb0  nn.batch_matmul77:0\n",
      "     tonga0:tpb0  nn.batch_matmul78:0\n",
      "     tonga0:tpb0  nn.batch_matmul79:0\n",
      "     tonga0:tpb0  nn.batch_matmul7:0\n",
      "     tonga0:tpb0  nn.batch_matmul80:0\n",
      "     tonga0:tpb0  nn.batch_matmul81:0\n",
      "     tonga0:tpb0  nn.batch_matmul82:0\n",
      "     tonga0:tpb0  nn.batch_matmul83:0\n",
      "     tonga0:tpb0  nn.batch_matmul84:0\n",
      "     tonga0:tpb0  nn.batch_matmul85:0\n",
      "     tonga0:tpb0  nn.batch_matmul86:0\n",
      "     tonga0:tpb0  nn.batch_matmul87:0\n",
      "     tonga0:tpb0  nn.batch_matmul88:0\n",
      "     tonga0:tpb0  nn.batch_matmul89:0\n",
      "     tonga0:tpb0  nn.batch_matmul8:0\n",
      "     tonga0:tpb0  nn.batch_matmul90:0\n",
      "     tonga0:tpb0  nn.batch_matmul91:0\n",
      "     tonga0:tpb0  nn.batch_matmul92:0\n",
      "     tonga0:tpb0  nn.batch_matmul93:0\n",
      "     tonga0:tpb0  nn.batch_matmul94:0\n",
      "     tonga0:tpb0  nn.batch_matmul95:0\n",
      "     tonga0:tpb0  nn.batch_matmul9:0\n",
      "     tonga0:tpb0  reshape101:0\n",
      "     tonga0:tpb0  reshape102:0\n",
      "     tonga0:tpb0  reshape105:0\n",
      "     tonga0:tpb0  reshape114:0\n",
      "     tonga0:tpb0  reshape117:0\n",
      "     tonga0:tpb0  reshape118:0\n",
      "     tonga0:tpb0  reshape121:0\n",
      "     tonga0:tpb0  reshape130:0\n",
      "     tonga0:tpb0  reshape133:0\n",
      "     tonga0:tpb0  reshape134:0\n",
      "     tonga0:tpb0  reshape137:0\n",
      "     tonga0:tpb0  reshape146:0\n",
      "     tonga0:tpb0  reshape149:0\n",
      "     tonga0:tpb0  reshape150:0\n",
      "     tonga0:tpb0  reshape153:0\n",
      "     tonga0:tpb0  reshape162:0\n",
      "     tonga0:tpb0  reshape165:0\n",
      "     tonga0:tpb0  reshape166:0\n",
      "     tonga0:tpb0  reshape169:0\n",
      "     tonga0:tpb0  reshape178:0\n",
      "     tonga0:tpb0  reshape181:0\n",
      "     tonga0:tpb0  reshape182:0\n",
      "     tonga0:tpb0  reshape185:0\n",
      "     tonga0:tpb0  reshape18:0\n",
      "     tonga0:tpb0  reshape21:0\n",
      "     tonga0:tpb0  reshape22:0\n",
      "     tonga0:tpb0  reshape25:0\n",
      "     tonga0:tpb0  reshape2:0\n",
      "     tonga0:tpb0  reshape34:0\n",
      "     tonga0:tpb0  reshape37:0\n",
      "     tonga0:tpb0  reshape38:0\n",
      "     tonga0:tpb0  reshape41:0\n",
      "     tonga0:tpb0  reshape50:0\n",
      "     tonga0:tpb0  reshape53:0\n",
      "     tonga0:tpb0  reshape54:0\n",
      "     tonga0:tpb0  reshape57:0\n",
      "     tonga0:tpb0  reshape5:0\n",
      "     tonga0:tpb0  reshape66:0\n",
      "     tonga0:tpb0  reshape69:0\n",
      "     tonga0:tpb0  reshape6:0\n",
      "     tonga0:tpb0  reshape70:0\n",
      "     tonga0:tpb0  reshape73:0\n",
      "     tonga0:tpb0  reshape82:0\n",
      "     tonga0:tpb0  reshape85:0\n",
      "     tonga0:tpb0  reshape86:0\n",
      "     tonga0:tpb0  reshape89:0\n",
      "     tonga0:tpb0  reshape98:0\n",
      "     tonga0:tpb0  reshape9:0\n",
      "     tonga0:tpb0  sqrt0:0\n",
      "     tonga0:tpb0  sqrt10:0\n",
      "     tonga0:tpb0  sqrt11:0\n",
      "     tonga0:tpb0  sqrt12:0\n",
      "     tonga0:tpb0  sqrt13:0\n",
      "     tonga0:tpb0  sqrt14:0\n",
      "     tonga0:tpb0  sqrt15:0\n",
      "     tonga0:tpb0  sqrt16:0\n",
      "     tonga0:tpb0  sqrt17:0\n",
      "     tonga0:tpb0  sqrt18:0\n",
      "     tonga0:tpb0  sqrt19:0\n",
      "     tonga0:tpb0  sqrt1:0\n",
      "     tonga0:tpb0  sqrt20:0\n",
      "     tonga0:tpb0  sqrt21:0\n",
      "     tonga0:tpb0  sqrt22:0\n",
      "     tonga0:tpb0  sqrt23:0\n",
      "     tonga0:tpb0  sqrt24:0\n",
      "     tonga0:tpb0  sqrt2:0\n",
      "     tonga0:tpb0  sqrt3:0\n",
      "     tonga0:tpb0  sqrt4:0\n",
      "     tonga0:tpb0  sqrt5:0\n",
      "     tonga0:tpb0  sqrt6:0\n",
      "     tonga0:tpb0  sqrt7:0\n",
      "     tonga0:tpb0  sqrt8:0\n",
      "     tonga0:tpb0  sqrt9:0\n",
      "     tonga0:tpb0  strided_slice0:0\n",
      "     tonga0:tpb0  strided_slice1:0\n",
      "     tonga0:tpb0  strided_slice2:0\n",
      "     tonga0:tpb0  subtract0:0\n",
      "     tonga0:tpb0  subtract10:0\n",
      "     tonga0:tpb0  subtract11:0\n",
      "     tonga0:tpb0  subtract12:0\n",
      "     tonga0:tpb0  subtract13:0\n",
      "     tonga0:tpb0  subtract14:0\n",
      "     tonga0:tpb0  subtract15:0\n",
      "     tonga0:tpb0  subtract16:0\n",
      "     tonga0:tpb0  subtract17:0\n",
      "     tonga0:tpb0  subtract18:0\n",
      "     tonga0:tpb0  subtract19:0\n",
      "     tonga0:tpb0  subtract1:0\n",
      "     tonga0:tpb0  subtract20:0\n",
      "     tonga0:tpb0  subtract21:0\n",
      "     tonga0:tpb0  subtract22:0\n",
      "     tonga0:tpb0  subtract23:0\n",
      "     tonga0:tpb0  subtract24:0\n",
      "     tonga0:tpb0  subtract2:0\n",
      "     tonga0:tpb0  subtract3:0\n",
      "     tonga0:tpb0  subtract4:0\n",
      "     tonga0:tpb0  subtract5:0\n",
      "     tonga0:tpb0  subtract6:0\n",
      "     tonga0:tpb0  subtract7:0\n",
      "     tonga0:tpb0  subtract8:0\n",
      "     tonga0:tpb0  subtract9:0\n",
      "     tonga0:tpb0  sum0:0\n",
      "     tonga0:tpb0  sum10:0\n",
      "     tonga0:tpb0  sum11:0\n",
      "     tonga0:tpb0  sum12:0\n",
      "     tonga0:tpb0  sum13:0\n",
      "     tonga0:tpb0  sum14:0\n",
      "     tonga0:tpb0  sum15:0\n",
      "     tonga0:tpb0  sum16:0\n",
      "     tonga0:tpb0  sum17:0\n",
      "     tonga0:tpb0  sum18:0\n",
      "     tonga0:tpb0  sum19:0\n",
      "     tonga0:tpb0  sum1:0\n",
      "     tonga0:tpb0  sum20:0\n",
      "     tonga0:tpb0  sum21:0\n",
      "     tonga0:tpb0  sum22:0\n",
      "     tonga0:tpb0  sum23:0\n",
      "     tonga0:tpb0  sum24:0\n",
      "     tonga0:tpb0  sum25:0\n",
      "     tonga0:tpb0  sum26:0\n",
      "     tonga0:tpb0  sum27:0\n",
      "     tonga0:tpb0  sum28:0\n",
      "     tonga0:tpb0  sum29:0\n",
      "     tonga0:tpb0  sum2:0\n",
      "     tonga0:tpb0  sum30:0\n",
      "     tonga0:tpb0  sum31:0\n",
      "     tonga0:tpb0  sum32:0\n",
      "     tonga0:tpb0  sum33:0\n",
      "     tonga0:tpb0  sum34:0\n",
      "     tonga0:tpb0  sum35:0\n",
      "     tonga0:tpb0  sum36:0\n",
      "     tonga0:tpb0  sum37:0\n",
      "     tonga0:tpb0  sum38:0\n",
      "     tonga0:tpb0  sum39:0\n",
      "     tonga0:tpb0  sum3:0\n",
      "     tonga0:tpb0  sum40:0\n",
      "     tonga0:tpb0  sum41:0\n",
      "     tonga0:tpb0  sum42:0\n",
      "     tonga0:tpb0  sum43:0\n",
      "     tonga0:tpb0  sum44:0\n",
      "     tonga0:tpb0  sum45:0\n",
      "     tonga0:tpb0  sum46:0\n",
      "     tonga0:tpb0  sum47:0\n",
      "     tonga0:tpb0  sum48:0\n",
      "     tonga0:tpb0  sum49:0\n",
      "     tonga0:tpb0  sum4:0\n",
      "     tonga0:tpb0  sum5:0\n",
      "     tonga0:tpb0  sum6:0\n",
      "     tonga0:tpb0  sum7:0\n",
      "     tonga0:tpb0  sum8:0\n",
      "     tonga0:tpb0  sum9:0\n",
      "     tonga0:tpb0  transpose10:0\n",
      "     tonga0:tpb0  transpose12:0\n",
      "     tonga0:tpb0  transpose18:0\n",
      "     tonga0:tpb0  transpose20:0\n",
      "     tonga0:tpb0  transpose26:0\n",
      "     tonga0:tpb0  transpose28:0\n",
      "     tonga0:tpb0  transpose2:0\n",
      "     tonga0:tpb0  transpose34:0\n",
      "     tonga0:tpb0  transpose36:0\n",
      "     tonga0:tpb0  transpose42:0\n",
      "     tonga0:tpb0  transpose44:0\n",
      "     tonga0:tpb0  transpose4:0\n",
      "     tonga0:tpb0  transpose50:0\n",
      "     tonga0:tpb0  transpose52:0\n",
      "     tonga0:tpb0  transpose58:0\n",
      "     tonga0:tpb0  transpose60:0\n",
      "     tonga0:tpb0  transpose66:0\n",
      "     tonga0:tpb0  transpose68:0\n",
      "     tonga0:tpb0  transpose74:0\n",
      "     tonga0:tpb0  transpose76:0\n",
      "     tonga0:tpb0  transpose82:0\n",
      "     tonga0:tpb0  transpose84:0\n",
      "     tonga0:tpb0  transpose90:0\n",
      "     tonga0:tpb0  transpose92:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "09/26/2023 05:07:56 PM INFO 20697 [job.Frontend.4]: IR signature: 5f48eb7542ebfc344b9494b5f465c9b94f5ef1cbe68a0a8573ac670076f2397a for relay_graph_post_opt_unit_level.txt\n",
      "09/26/2023 05:07:56 PM INFO 20697 [root/Tensorizer/All]: Enter time region\n",
      "09/26/2023 05:07:56 PM INFO 20697 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "09/26/2023 05:07:56 PM INFO 20697 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "09/26/2023 05:07:57 PM INFO 20697 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.658s\n",
      "09/26/2023 05:07:57 PM INFO 20697 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "09/26/2023 05:07:58 PM INFO 20697 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=1.425s\n",
      "09/26/2023 05:07:58 PM INFO 20697 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "09/26/2023 05:07:58 PM INFO 20697 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "09/26/2023 05:07:58 PM INFO 20697 [Statistics]: Weights total number of bytes: 342592812\n",
      "09/26/2023 05:07:58 PM INFO 20697 [Statistics]: RelayIF total number of bytes: 393728.0\n",
      "09/26/2023 05:07:58 PM INFO 20697 [Statistics]: RelayOF total number of bytes: 8.0\n",
      "09/26/2023 05:07:58 PM INFO 20697 [Statistics]: Weights total number of bytes: 342592812.0\n",
      "09/26/2023 05:07:58 PM INFO 20697 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "09/26/2023 05:07:59 PM INFO 20697 [DoNothing]: Finished (changed=False)\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.270s\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "09/26/2023 05:07:59 PM INFO 20697 [MutateDataType]: Finished (changed=False)\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.262s\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "09/26/2023 05:07:59 PM INFO 20697 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.263s\n",
      "09/26/2023 05:07:59 PM INFO 20697 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "09/26/2023 05:08:00 PM INFO 20697 [EliminateDivs]: Finished (changed=False)\n",
      "09/26/2023 05:08:00 PM INFO 20697 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.266s\n",
      "09/26/2023 05:08:00 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "09/26/2023 05:08:00 PM INFO 20697 [SimplifyPredicates]: Finished (changed=False)\n",
      "09/26/2023 05:08:00 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.563s\n",
      "09/26/2023 05:08:00 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:01 PM INFO 20697 [Simplifier]: Finished (changed=True #instances=56215414160)\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.701s\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "09/26/2023 05:08:01 PM INFO 20697 [TCTransform]: Finished (changed=True #instances=45041196944)\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.298s\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "09/26/2023 05:08:01 PM INFO 20697 [CommuteConcat]: Finished (changed=False)\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.264s\n",
      "09/26/2023 05:08:01 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "09/26/2023 05:08:04 PM INFO 20697 [LoopFusion]: Finished (changed=True #instances=94185661440)\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=2.251s\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:04 PM INFO 20697 [Simplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.165s\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "09/26/2023 05:08:04 PM INFO 20697 [DelinearIndices]: Finished (changed=True #instances=94185661440)\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.300s\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "09/26/2023 05:08:04 PM INFO 20697 [Delinearization]: Finished (changed=False)\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.131s\n",
      "09/26/2023 05:08:04 PM INFO 20697 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "09/26/2023 05:08:06 PM INFO 20697 [DeadStoreElimination]: Finished (changed=True #instances=87297669120)\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=1.736s\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:06 PM INFO 20697 [Simplifier]: Finished (changed=True #instances=87297669120)\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.347s\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:06 PM INFO 20697 [LICM]: Finished (changed=True #instances=31335397206)\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.102s\n",
      "09/26/2023 05:08:06 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "09/26/2023 05:08:07 PM INFO 20697 [DelinearIndices]: Finished (changed=True #instances=31335397206)\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.133s\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "09/26/2023 05:08:07 PM INFO 20697 [Delinearization]: Finished (changed=False)\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.129s\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "09/26/2023 05:08:07 PM INFO 20697 [LoopFusion]: Finished (changed=True #instances=31331073360)\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.328s\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:07 PM INFO 20697 [LICM]: Finished (changed=True #instances=31331068758)\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.083s\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:07 PM INFO 20697 [Simplifier]: Finished (changed=True #instances=31331068748)\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.324s\n",
      "09/26/2023 05:08:07 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [ValueNumbering]: Finished (changed=True #instances=31328806220)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.155s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [LICM]: Finished (changed=False)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.069s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [MemcpyElimination]: Finished (changed=True #instances=31328413004)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.193s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [PadElimination]: Finished (changed=False)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.065s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [DelinearIndices]: Finished (changed=False)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.102s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [Delinearization]: Finished (changed=False)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.113s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "09/26/2023 05:08:08 PM INFO 20697 [LoopFusion]: Finished (changed=True #instances=31328409932)\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.306s\n",
      "09/26/2023 05:08:08 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [Simplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.154s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [LICM]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.068s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [ValueNumbering]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.096s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [TCTransform]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.071s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [CommuteConcat]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.073s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [LoopFusion]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.200s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [ValueNumbering]: Finished (changed=False)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.095s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "09/26/2023 05:08:09 PM INFO 20697 [RecognizeOpIdiom]: Finished (changed=True #instances=31311093194)\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.241s\n",
      "09/26/2023 05:08:09 PM INFO 20697 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [DeadCodeElimination]: Finished (changed=False)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.073s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [Tensorizer]: After optimization: 1 statements\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [AutoCastFP32]: Finished (changed=True #instances=31311388492)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.089s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [LoopFusion]: Finished (changed=False)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.197s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [Simplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.137s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [Delinearization]: Finished (changed=True #instances=31311388492)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.138s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "09/26/2023 05:08:10 PM INFO 20697 [ResolveAccessConflict]: Finished (changed=True #instances=31326879270)\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.212s\n",
      "09/26/2023 05:08:10 PM INFO 20697 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "09/26/2023 05:08:11 PM INFO 20697 [TransformLayout]: Finished (changed=True #instances=31349406374)\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.453s\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "09/26/2023 05:08:11 PM INFO 20697 [PartitionLocalityOpt]: Finished (changed=True #instances=31349406374)\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.201s\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "09/26/2023 05:08:11 PM INFO 20697 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.093s\n",
      "09/26/2023 05:08:11 PM INFO 20697 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "09/26/2023 05:08:13 PM INFO 20697 [TongaSizeTiling]: Finished (changed=True #instances=10060)\n",
      "09/26/2023 05:08:13 PM INFO 20697 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=1.996s\n",
      "09/26/2023 05:08:13 PM INFO 20697 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "09/26/2023 05:08:13 PM INFO 20697 [TilingProfiler]: Finished (changed=False)\n",
      "09/26/2023 05:08:13 PM INFO 20697 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.190s\n",
      "09/26/2023 05:08:13 PM INFO 20697 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "09/26/2023 05:08:13 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "09/26/2023 05:08:14 PM INFO 20697 [FlattenMacroLoop]: Finished (changed=True #instances=10060)\n",
      "09/26/2023 05:08:14 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.215s\n",
      "09/26/2023 05:08:14 PM INFO 20697 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "09/26/2023 05:08:14 PM INFO 20697 [RetileSIMDMacro]: Finished (changed=False)\n",
      "09/26/2023 05:08:14 PM INFO 20697 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.150s\n",
      "09/26/2023 05:08:14 PM INFO 20697 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "09/26/2023 05:08:15 PM INFO 20697 [InferTongaTensor]: Finished (changed=True #instances=10060)\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.828s\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "09/26/2023 05:08:15 PM INFO 20697 [TongaSimplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.197s\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:15 PM INFO 20697 [LICM]: Finished (changed=True #instances=10060)\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.173s\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "09/26/2023 05:08:15 PM INFO 20697 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.174s\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "09/26/2023 05:08:15 PM INFO 20697 [FlattenMacroLoop]: Finished (changed=True #instances=10060)\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.226s\n",
      "09/26/2023 05:08:15 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "09/26/2023 05:08:16 PM INFO 20697 [SimplifyPredicates]: Finished (changed=False)\n",
      "09/26/2023 05:08:16 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.340s\n",
      "09/26/2023 05:08:16 PM INFO 20697 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "09/26/2023 05:08:21 PM INFO 20697 [DataLocalityOpt]: Finished (changed=True #instances=10659)\n",
      "09/26/2023 05:08:21 PM INFO 20697 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=5.240s\n",
      "09/26/2023 05:08:21 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "09/26/2023 05:08:21 PM INFO 20697 [TongaSimplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:21 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.258s\n",
      "09/26/2023 05:08:21 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "09/26/2023 05:08:22 PM INFO 20697 [LegalizeTongaMacro]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.377s\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "09/26/2023 05:08:22 PM INFO 20697 [TongaSimplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.282s\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "09/26/2023 05:08:22 PM INFO 20697 [PerfectLoopNest]: Finished (changed=False)\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.257s\n",
      "09/26/2023 05:08:22 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "09/26/2023 05:08:23 PM INFO 20697 [FlattenMacroLoop]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:23 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.359s\n",
      "09/26/2023 05:08:23 PM INFO 20697 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM WARNING 20697 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "09/26/2023 05:08:25 PM INFO 20697 [RewriteWeights]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:25 PM INFO 20697 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=2.633s\n",
      "09/26/2023 05:08:25 PM INFO 20697 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "09/26/2023 05:08:25 PM INFO 20697 [ReshapeWeights]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:25 PM INFO 20697 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.289s\n",
      "09/26/2023 05:08:25 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "09/26/2023 05:08:26 PM INFO 20697 [FlattenMacroLoop]: Finished (changed=False)\n",
      "09/26/2023 05:08:26 PM INFO 20697 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.246s\n",
      "09/26/2023 05:08:26 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "09/26/2023 05:08:26 PM INFO 20697 [SimplifyPredicates]: Finished (changed=False)\n",
      "09/26/2023 05:08:26 PM INFO 20697 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.488s\n",
      "09/26/2023 05:08:26 PM INFO 20697 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "09/26/2023 05:08:28 PM INFO 20697 [InferInitValue]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:28 PM INFO 20697 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=1.832s\n",
      "09/26/2023 05:08:28 PM INFO 20697 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "09/26/2023 05:08:28 PM INFO 20697 [SplitUnionSets]: Finished (changed=False)\n",
      "09/26/2023 05:08:28 PM INFO 20697 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.235s\n",
      "09/26/2023 05:08:28 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "09/26/2023 05:08:29 PM INFO 20697 [TongaSimplifier]: Finished (changed=False)\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.272s\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "09/26/2023 05:08:29 PM INFO 20697 [SimplifyTongaTensor]: Finished (changed=True #instances=10852)\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.644s\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "09/26/2023 05:08:29 PM INFO 20697 [LegalizeTongaStore]: Finished (changed=False)\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.273s\n",
      "09/26/2023 05:08:29 PM INFO 20697 [sg00/Tensorizer/LICM]: Enter time region\n",
      "09/26/2023 05:08:30 PM INFO 20697 [LICM]: Finished (changed=False)\n",
      "09/26/2023 05:08:30 PM INFO 20697 [sg00/Tensorizer/LICM]: Exit time region: delta=0.241s\n",
      "09/26/2023 05:08:30 PM INFO 20697 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "09/26/2023 05:08:31 PM INFO 20697 [TongaISel]: Finished (changed=True #instances=13670)\n",
      "09/26/2023 05:08:31 PM INFO 20697 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.803s\n",
      "09/26/2023 05:08:31 PM INFO 20697 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "09/26/2023 05:08:31 PM INFO 20697 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "09/26/2023 05:08:31 PM INFO 20697 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.263s\n",
      "09/26/2023 05:08:31 PM INFO 20697 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "09/26/2023 05:08:32 PM INFO 20697 [TongaLoopFusion]: Finished (changed=True #instances=13670)\n",
      "09/26/2023 05:08:32 PM INFO 20697 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=1.404s\n",
      "09/26/2023 05:08:32 PM INFO 20697 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "09/26/2023 05:08:32 PM INFO 20697 [TongaLICM]: Finished (changed=False)\n",
      "09/26/2023 05:08:32 PM INFO 20697 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.253s\n",
      "09/26/2023 05:08:32 PM INFO 20697 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "09/26/2023 05:08:33 PM INFO 20697 [FactorizeBlkDims]: Finished (changed=True #instances=13670)\n",
      "09/26/2023 05:08:33 PM INFO 20697 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.900s\n",
      "09/26/2023 05:08:33 PM INFO 20697 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "09/26/2023 05:08:34 PM INFO 20697 [TongaInstComb]: Finished (changed=True #instances=12166)\n",
      "09/26/2023 05:08:34 PM INFO 20697 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.843s\n",
      "09/26/2023 05:08:34 PM INFO 20697 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "09/26/2023 05:08:35 PM INFO 20697 [TongaValueNumbering]: Finished (changed=True #instances=11899)\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.298s\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "09/26/2023 05:08:35 PM INFO 20697 [LowerTranspose]: Finished (changed=True #instances=12328)\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.347s\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "09/26/2023 05:08:35 PM INFO 20697 [LegalizeTongaType]: Finished (changed=True #instances=12613)\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.266s\n",
      "09/26/2023 05:08:35 PM INFO 20697 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "09/26/2023 05:08:37 PM INFO 20697 [PartialLoopFusion]: Finished (changed=True #instances=12613)\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=1.628s\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "09/26/2023 05:08:37 PM INFO 20697 [ShortenLifeInterval]: Finished (changed=True #instances=12613)\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.338s\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "09/26/2023 05:08:37 PM INFO 20697 [GlobalBatchOpt]: Finished (changed=False)\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.222s\n",
      "09/26/2023 05:08:37 PM INFO 20697 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "09/26/2023 05:08:38 PM INFO 20697 [SpillPSum]: Finished (changed=True #instances=12757)\n",
      "09/26/2023 05:08:38 PM INFO 20697 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.430s\n",
      "09/26/2023 05:08:38 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "09/26/2023 05:08:38 PM INFO 20697 [LegalizeTongaType]: Finished (changed=False)\n",
      "09/26/2023 05:08:38 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.234s\n",
      "09/26/2023 05:08:38 PM INFO 20697 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "09/26/2023 05:08:39 PM INFO 20697 [InferPSumTensor]: Finished (changed=True #instances=12757)\n",
      "09/26/2023 05:08:39 PM INFO 20697 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=1.079s\n",
      "09/26/2023 05:08:39 PM INFO 20697 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "09/26/2023 05:08:39 PM INFO 20697 [VectorizeMatMult]: Finished (changed=False)\n",
      "09/26/2023 05:08:39 PM INFO 20697 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.244s\n",
      "09/26/2023 05:08:39 PM INFO 20697 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "09/26/2023 05:08:40 PM INFO 20697 [WeightCoalescing]: Finished (changed=True #instances=12670)\n",
      "09/26/2023 05:08:40 PM INFO 20697 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.267s\n",
      "09/26/2023 05:08:40 PM INFO 20697 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "09/26/2023 05:08:41 PM INFO 20697 [LowerPartitionTile]: Finished (changed=True #instances=21402)\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=1.084s\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "09/26/2023 05:08:41 PM INFO 20697 [BroadcastWeights]: Finished (changed=False)\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.306s\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "09/26/2023 05:08:41 PM INFO 20697 [TensorInitialization]: Finished (changed=False)\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.310s\n",
      "09/26/2023 05:08:41 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "09/26/2023 05:08:42 PM INFO 20697 [LegalizeTongaAccess]: Finished (changed=True #instances=21402)\n",
      "09/26/2023 05:08:42 PM INFO 20697 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.574s\n",
      "09/26/2023 05:08:42 PM INFO 20697 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "09/26/2023 05:08:42 PM INFO 20697 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "09/26/2023 05:08:42 PM INFO 20697 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.312s\n",
      "09/26/2023 05:08:42 PM INFO 20697 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "09/26/2023 05:08:43 PM INFO 20697 [RelaxPredicates]: Finished (changed=False)\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.321s\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "09/26/2023 05:08:43 PM INFO 20697 [TensorInitialization]: Finished (changed=False)\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.310s\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "09/26/2023 05:08:43 PM INFO 20697 [ExpandISAMacro]: Finished (changed=False)\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.318s\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "09/26/2023 05:08:43 PM INFO 20697 [LegalizePartitionTile]: Finished (changed=False)\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.312s\n",
      "09/26/2023 05:08:43 PM INFO 20697 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "09/26/2023 05:08:44 PM INFO 20697 [SimplifyTongaTensor]: Finished (changed=True #instances=21402)\n",
      "09/26/2023 05:08:44 PM INFO 20697 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.683s\n",
      "09/26/2023 05:08:44 PM INFO 20697 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "09/26/2023 05:08:45 PM INFO 20697 [LinearizeFreeDim]: Finished (changed=True #instances=21402)\n",
      "09/26/2023 05:08:45 PM INFO 20697 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.328s\n",
      "09/26/2023 05:08:45 PM INFO 20697 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "09/26/2023 05:08:45 PM INFO 20697 [DataStreaming]: Finished (changed=False)\n",
      "09/26/2023 05:08:45 PM INFO 20697 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.364s\n",
      "09/26/2023 05:08:45 PM INFO 20697 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "09/26/2023 05:08:47 PM INFO 20697 [ILPOpt]: Finished (changed=True #instances=21152)\n",
      "09/26/2023 05:08:47 PM INFO 20697 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=2.367s\n",
      "09/26/2023 05:08:47 PM INFO 20697 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "09/26/2023 05:08:48 PM INFO 20697 [StaticProfiler]: Finished (changed=False)\n",
      "09/26/2023 05:08:48 PM INFO 20697 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.382s\n",
      "09/26/2023 05:08:48 PM INFO 20697 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "09/26/2023 05:08:48 PM INFO 20697 [LowerAPIndices]: Finished (changed=True #instances=21156)\n",
      "09/26/2023 05:08:48 PM INFO 20697 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.709s\n",
      "09/26/2023 05:08:48 PM INFO 20697 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "09/26/2023 05:08:49 PM INFO 20697 [LowerMisc]: Finished (changed=False)\n",
      "09/26/2023 05:08:49 PM INFO 20697 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.195s\n",
      "09/26/2023 05:08:49 PM INFO 20697 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "09/26/2023 05:08:49 PM INFO 20697 [BirCodeGenLoop]: Finished (changed=False)\n",
      "09/26/2023 05:08:49 PM INFO 20697 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.380s\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Tensorizer]: IR signature: ecfc91fcf376643e479c14a868e577ad21828c77d499e67a1c9c208fe5ae340d for sg00/Tensorizer\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Tensorizer]: Weights total number of bytes: 171877380\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Tensorizer]: Finalize\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]: --- Penguin Statistics ---\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:           122880  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               80  DTypeMutator      Number of load whose tensor type mutated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               18  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              197  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              200  DataLocalityOpt   Number of prefetch inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                1  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          7036816  DeadStoreElimination  Number of bytes eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              831  DelinearizationBase  Number of tensors delinearized\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              595  FlattenMacroLoop  Number of axes coalesced\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              371  FlattenMacroLoop  Number of tensors reshaped\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               51  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         17713152  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              516  InferTongaTensor  Number of local tensor inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        102378824  InferTongaTensor  Total number of bytes of local tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               42  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                4  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             1388  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              817  LoopFusion        Number of loops fused\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               18  LoopFusion        Number of trivial copy eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              154  LowerPartitionTile  Number of matmult instruction lowered\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              563  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              110  LowerTranspose    Number of lossless transpose generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                2  LowerTranspose    Number of lossy transpose generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:           786432  MemcpyElimination  Number of bytes copied by memcpy\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:           786432  MemcpyElimination  Number of bytes eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                2  MemcpyElimination  Number of memcopy eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              405  ModDivDelinear    Number of loops tiled by delinearization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               49  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              341  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              131  PartialLoopFusion  Number of loops fused\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               95  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               12  RecognizeOpIdiom  Number of gelu inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               25  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:      11174217216  RelayFE           Number of MAC count in relay\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        897394500  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              198  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               23  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              173  SimplifyTensorBase  Number of tensors simplified\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              173  SimplifyTensorBase  Number of tensors squeezed\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          9437184  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:       59694.3242  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:       59694.3242  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        2910.3307  StaticProfiler    Average dma length per-partition\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        1197.3333  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          90.4226  StaticProfiler    Average partition utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          88.7769  StaticProfiler    Average pe (systolic array) utilization\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             3072  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:           0.4246  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             1483  StaticProfiler    Num of matmul transpose instructions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:      23503804434  StaticProfiler    Number of arithmetic computation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          8758928  StaticProfiler    Number of arithmetic computation by activation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:      23457602560  StaticProfiler    Number of arithmetic computation by matmul\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:            16908  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          8813796  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          2184080  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         15213056  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         11215106  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         31220556  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        171484676  StaticProfiler    Number of bytes of weights loaded\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          1492318  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        171878412  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               14  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:            13593  StaticProfiler    Number of matmul instructions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              870  StaticProfiler    Number of tensorcopy after transpose\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             1014  StaticProfiler    Number of tensorcopy from psum\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             1638  StaticProfiler    Number of tensorcopy instructions\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:            22131  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          35.7754  StaticProfiler    Utilized psum size / Max psum size\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:          90.4056  TilingProfiler    Average partition utilization calculated after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:         145.3976  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:             7380  TilingProfiler    Number of insts from matmults after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              740  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                7  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              733  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              316  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              111  TilingProfiler    Number of pf transposes\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                2  TilingProfiler    Number of pf transposes for IO tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              109  TilingProfiler    Number of pf transposes for local tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:            10060  TilingProfiler    Number of total insts after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              116  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               39  TongaInstComb     Number of bias_add combined to activation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               25  TongaInstComb     Number of scale combined to activation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              259  TongaInstComb     Number of trivial access pattern eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              273  TongaLoopFusion   Number of loops fused\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              109  TongaSizeTiling   Number of inherit tiles\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                8  TongaSizeTiling   Number of places global layout clobbered\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               25  TongaValueNumbering  Number of instructions deleted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                1  TongaValueNumbering  Number of tensors deleted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:              111  TransformLayoutPass  Number of transpose inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               25  ValueNumbering    Number of instructions deleted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               68  Vectorizer        Number of instruction vectorized\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               96  WeightCoalescing  Number of empty loopnest eliminated\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:               96  WeightCoalescing  Number of load instruction merged\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:        342592516  WeightRewriter    Number of bytes re-written for weights\n",
      "09/26/2023 05:08:50 PM INFO 20697 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "09/26/2023 05:08:50 PM INFO 20697 [root/Tensorizer/All]: Exit time region: delta=54.043s\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.Frontend.4]: wrote bir.json\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.Frontend.4]: wrote tensor_map.json\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.Frontend.4]: End tensorization\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.Frontend.4]: Job finished\n",
      "09/26/2023 05:08:51 PM INFO 20697 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "09/26/2023 05:08:51 PM INFO 20697 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.HHChecker.0]: Job finished\n",
      "09/26/2023 05:08:51 PM INFO 20697 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "09/26/2023 05:08:51 PM INFO 20697 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "09/26/2023 05:08:51 PM INFO 20697 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/26/2023 05:08:51 PM INFO [WalrusDriver.0]: max_allowed_parallelism=16\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=1081 blocks=1 instructions=216\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Total count: 20452\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Matmult: 13401\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: TensorScalarPtr: 1837\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: TensorCopy: 1530\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: TensorTensor: 1165\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Activation: 959\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Load: 513\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: TensorReduce: 428\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: TensorScalar: 405\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Shuffle: 97\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Reciprocal: 67\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Memset: 49\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Save: 1\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0.04 seconds\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0.028 seconds\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 513 loads, 1 saves, 0 copies.\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start DCE Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End DCE Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Tue Sep 26 17:08:52 2023\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "09/26/2023 05:08:52 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 171878412\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 3012 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 2559\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 409281 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: 150% PSUM demand before spilling\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 6 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 1456 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 11648 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             lo = 2362\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             hi = 100\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             inf = 97\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             total = 2559\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 27\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           PSUM spills = 27 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         PSUM score = 14578 (lower is better)\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best PSUM heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       collect spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       insert spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 2562\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 410241 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 4 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 1264 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 10112 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             lo = 2534\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             hi = 27\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             inf = 1\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             total = 2562\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           no more spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 14578 cycles\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: number of tensors spilled from PSUM = 27\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: 100% PSUM utilization after allocation\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/MatMul_t9237_i6\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find first defs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find loads\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         511 pin count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         511 pinned tensors will require about 1484504 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: 1518% SB demand before allocation\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB high-water mark = 1492456 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             1492456 bytes in partitions [0, 31]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             1492456 bytes in partitions [32, 63]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             1245784 bytes in partitions [64, 95]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             1245784 bytes in partitions [96, 127]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 1683789 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 13470312 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:               safe = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             unsafe = 2880\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                inf = 580\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 496\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:            unpinned = 475 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 1407120 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         SB score = 1.62953e+07\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       collect spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       insert spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/MatMul_t9237_i6\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find first defs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find loads\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         36 pin count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         475 remat count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         36 pinned tensors will require about 85208 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB high-water mark = 101128 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             101128 bytes in partitions [0, 31]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             101128 bytes in partitions [32, 63]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             99544 bytes in partitions [64, 95]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             99544 bytes in partitions [96, 127]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 186382 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 1491056 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:               safe = 493\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             unsafe = 2471\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                inf = 496\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 29\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:            unpinned = 8 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 8168 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         SB score = 108393\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       collect spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       insert spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/MatMul_t9237_i6\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find first defs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find loads\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         28 pin count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         483 remat count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         28 pinned tensors will require about 77040 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB high-water mark = 94200 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             94200 bytes in partitions [0, 31]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             94200 bytes in partitions [32, 63]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             93360 bytes in partitions [64, 95]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             93360 bytes in partitions [96, 127]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 168023 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 1344184 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:               safe = 971\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             unsafe = 2038\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                inf = 451\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 22\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:            unpinned = 1 tensors\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                size = 3072 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         SB score = 39821\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       collect spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       insert spills\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:     main loop\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/MatMul_t9237_i6\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find first defs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find loads\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         27 pin count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         484 remat count\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         27 pinned tensors will require about 73968 bytes/partition\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 1\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           SB high-water mark = 91128 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             91128 bytes in partitions [0, 31]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             91128 bytes in partitions [32, 63]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             90288 bytes in partitions [64, 95]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             90288 bytes in partitions [96, 127]\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         pass 2\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         found 164619 edges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         adjacency vectors require 1316952 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       find costs\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:               safe = 1413\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             unsafe = 1607\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:                inf = 440\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           simplify\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:             new candidates = 21\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         select ranges\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:           success\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: spilling from SB cost about 1.64435e+07 cycles\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: number of tensors unpinned from SB = 484\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: total size of unpinned tensors = 1418360 bytes/partition\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: tried to pin 1484504 bytes/partition\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: 73968 bytes/partition (4%) successfully pinned\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: pinning saved approximately 960174 cycles\n",
      "09/26/2023 05:08:53 PM WARNING [WalrusDriver.0]: 92% SB utilization after allocation\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 171878412, 100% input load, 4.65445e-06% output write, 0% spill/reload \n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 171878412, 100% input load, 4.65445e-06% output write, 0% spill/reload \n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 171878404\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 3012 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 8\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 171878404\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 3012 bytes\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 8\n",
      "09/26/2023 05:08:53 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: SB Rotation rotated 41 Sb address, reduced 14 consecutive Load overlapping address \n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "09/26/2023 05:08:54 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:54 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Tue Sep 26 17:08:54 2023\n",
      "09/26/2023 05:08:55 PM INFO [TheScheduler.0]: Done  PosT ScheD Tue Sep 26 17:08:55 2023\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "09/26/2023 05:08:55 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/sg00\"\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 171878412\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 3012 bytes\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Loads in Func = 513\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Saves in Func = 1\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Input Loads in Func= 513\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Output Saves in Func= 1\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]:     Engine              File\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]:     ------              ----\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: \n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: Data race checker engines\n",
      "09/26/2023 05:08:55 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Data race checker engines\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Transitive reduction removed 24 redundant edges, time: 0:00:00\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Sync Critical Load Chains added 161 new Load-2-Load syncs\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "09/26/2023 05:08:56 PM WARNING [Stargazer.0]: SBUF DMA write size != 0 mod 4: SBUF address=0x10808, size=2\n",
      "09/26/2023 05:08:56 PM WARNING [Stargazer.0]: SBUF DMA write size != 0 mod 4: SBUF address=0x141880, size=2\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "09/26/2023 05:08:56 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "09/26/2023 05:08:57 PM INFO [Stargazer.0]: Virtual memory peak = 4758788 K bytes\n",
      "09/26/2023 05:08:57 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:02\n",
      "09/26/2023 05:08:57 PM INFO [WalrusDriver.0]: ru_maxrss:  3698mb (delta=0mb)\n",
      "09/26/2023 05:08:57 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "09/26/2023 05:08:57 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/26/2023 05:09:03 PM INFO 20697 [job.WalrusDriver.3]: IR signature: a108c70e6df278b5caf2b85790c7260858f3acf0333f4d04cf73480e97cb7f62 for sg00/walrus_bir.out.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.WalrusDriver.3]: Job finished\n",
      "09/26/2023 05:09:03 PM INFO 20697 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "09/26/2023 05:09:03 PM INFO 20697 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: IR signature: de149e46e988b436a2db4e85facf764f785082e487fac49d0843509ef628ddb7 for sg00/wavegraph-bin.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: IR signature: 9c8151d0c0be3fc70a00ae86bc3d9b83cb1704742882285f4068e5a9b003ed3b for sg00/def.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: IR signature: 8b51999e31cc67e995076f45ad85d64863526881454b73d783665407130d1e3d for sg00/pool.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: IR signature: ed68ec0cab7f853899a886f328af8386ce157a404f71e5e103b80ac27bd8391d for sg00/act.json\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Backend.3]: Job finished\n",
      "09/26/2023 05:09:03 PM INFO 20697 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "09/26/2023 05:09:03 PM INFO 20697 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "09/26/2023 05:09:03 PM INFO 20697 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/pytorch_p310/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3703-8479-9827-10223_CRSM_0.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3703-8479-9827-10223_CRSM_1.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3731-8498-9831-10227_CRSM_0.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3731-8498-9831-10227_CRSM_1.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3833-8517-9835-10231_CRSM_0.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3833-8517-9835-10231_CRSM_1.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3975-8570-9847-10243_CRSM_0.npy\n",
      "09/26/2023 05:09:20 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3975-8570-9847-10243_CRSM_1.npy\n",
      "09/26/2023 05:09:21 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t4779-8860-9911-10307_CRSM_0.npy\n",
      "09/26/2023 05:09:21 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t4779-8860-9911-10307_CRSM_1.npy\n",
      "09/26/2023 05:09:22 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "09/26/2023 05:09:22 PM WARNING 20697 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "09/26/2023 05:09:22 PM INFO 20697 [job.Kelper.2]: neuroncc version is 1.19.0.0+b2910beb2, neff version is 1.0 (features 0)\n",
      "09/26/2023 05:09:22 PM INFO 20697 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/Sagemaker-BYOC/compilation_artifacts/60/graph_def.neff\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.compile.0]: Finished pipeline compile\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.compile.0]: Job finished\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.custom.0]: Finished pipeline custom\n",
      "09/26/2023 05:09:22 PM INFO 20697 [pipeline.custom.0]: Job finished\n",
      "09/26/2023 05:09:22 PM INFO 20697 [root]: Compiler status PASS\n",
      "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 565, compiled = 548, percent compiled = 96.99%\n",
      "INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
      "INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
      "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 96\n",
      "INFO:Neuron: => aten::add: 36\n",
      "INFO:Neuron: => aten::contiguous: 12\n",
      "INFO:Neuron: => aten::div: 12\n",
      "INFO:Neuron: => aten::dropout: 38\n",
      "INFO:Neuron: => aten::gelu: 12\n",
      "INFO:Neuron: => aten::layer_norm: 25\n",
      "INFO:Neuron: => aten::linear: 74\n",
      "INFO:Neuron: => aten::matmul: 24\n",
      "INFO:Neuron: => aten::permute: 48\n",
      "INFO:Neuron: => aten::select: 1\n",
      "INFO:Neuron: => aten::size: 96\n",
      "INFO:Neuron: => aten::slice: 1\n",
      "INFO:Neuron: => aten::softmax: 12\n",
      "INFO:Neuron: => aten::tanh: 1\n",
      "INFO:Neuron: => aten::transpose: 12\n",
      "INFO:Neuron: => aten::view: 48\n",
      "INFO:Neuron:Not compiled operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 1 [supported]\n",
      "INFO:Neuron: => aten::add: 2 [supported]\n",
      "INFO:Neuron: => aten::add_: 1 [supported]\n",
      "INFO:Neuron: => aten::embedding: 3 [not supported]\n",
      "INFO:Neuron: => aten::mul: 1 [supported]\n",
      "INFO:Neuron: => aten::rsub: 1 [supported]\n",
      "INFO:Neuron: => aten::size: 1 [supported]\n",
      "INFO:Neuron: => aten::slice: 4 [supported]\n",
      "INFO:Neuron: => aten::to: 1 [supported]\n",
      "INFO:Neuron: => aten::unsqueeze: 2 [supported]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.9 s, sys: 4.09 s, total: 39 s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run torch.neuron.trace to generate a TorchScript that is optimized by AWS Neuron\n",
    "# This step may need 3-5 min\n",
    "model_neuron = torch.neuron.trace(model, example_inputs_paraphrase, verbose=1, compiler_workdir='./compilation_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4752ac",
   "metadata": {},
   "source": [
    "You may inspect **model_neuron.graph** to see which part is running on CPU versus running on the accelerator. All native **aten** operators in the graph will be running on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc00889e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.torch_neuron.runtime.___torch_mangle_446.AwsNeuronGraphModule,\n",
      "      %7 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %tensor.1 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %9 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu)):\n",
      "  %_NeuronGraph#60 : __torch__.torch_neuron.decorators.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#60\"](%self.1)\n",
      "  %16 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %17 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %18 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %19 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %20 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.1, %16, %17, %18, %19) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %21 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %22 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %23 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %24 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %25 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = aten::slice(%20, %21, %22, %23, %24) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %26 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %27 : Long(1, 1, 128, strides=[128, 128, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%25, %26) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %28 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %tensor.3 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%27, %28) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %42 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %43 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %44 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %45 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %46 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.3, %42, %43, %44, %45) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %47 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %48 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %49 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %50 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %51 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%46, %47, %48, %49, %50) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %52 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %53 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %54 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %55 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %56 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%51, %52, %53, %54, %55) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %57 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %58 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %59 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %60 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %tensor.5 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%56, %57, %58, %59, %60) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %62 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:70:0\n",
      "  %63 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:70:0\n",
      "  %64 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:70:0\n",
      "  %65 : NoneType = prim::Constant()\n",
      "  %66 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %62, %63, %64, %65) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:70:0\n",
      "  %67 : float = prim::Constant[value=1.]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %68 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %69 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::rsub(%66, %67, %68) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %70 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-3.38953e+38}]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %71 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::mul(%69, %70) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %tensor.7 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:28:0\n",
      "  %90 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %91 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %92 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %93 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %94 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %90, %91, %92, %93) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %95 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %96 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %97 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %98 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %tensor : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%94, %95, %96, %97, %98) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %106 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %107 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %108 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %109 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %110 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor, %106, %107, %108, %109) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %111 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %112 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %113 : int = prim::Constant[value=128]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %114 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %115 : Long(1, 128, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%110, %111, %112, %113, %114) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/native_ops/aten.py:29:0\n",
      "  %116 : Float(28996, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %117 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %118 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %119 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %120 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%116, %7, %117, %118, %119) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %121 : Float(2, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %122 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %123 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %124 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %125 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%121, %9, %122, %123, %124) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %126 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %127 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::add(%120, %125, %126) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %128 : Float(512, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %129 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %130 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %131 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %132 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%128, %115, %129, %130, %131) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %133 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %134 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::add_(%127, %132, %133) # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch_neuron/resolve_function.py:67:0\n",
      "  %model : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#60)\n",
      "  %144 : Tensor[] = prim::ListConstruct(%134, %71), scope: __module._NeuronGraph#60\n",
      "  %145 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%144, %model), scope: __module._NeuronGraph#60 # /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_ops.py:442:0\n",
      "  %137 : (Float(1, 2, strides=[2, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%145)\n",
      "  return (%137)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See  which part is running on CPU versus running on the accelerator.\n",
    "print(model_neuron.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fb30d",
   "metadata": {},
   "source": [
    "Save the compiled model, so it can be packaged and sent to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027c4f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the TorchScript for later use\n",
    "model_neuron.save('neuron_compiled_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362c579",
   "metadata": {},
   "source": [
    "### Package the pre-trained model and upload it to S3\n",
    "\n",
    "To make the model available for the SageMaker deployment, you will TAR the serialized graph and upload it to the default Amazon S3 bucket for your SageMaker session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c7f7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron_compiled_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Now you'll create a model.tar.gz file to be used by SageMaker endpoint\n",
    "!tar -czvf model.tar.gz neuron_compiled_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1beadca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ad87d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload model to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "sess=sagemaker.Session()\n",
    "region=sess.boto_region_name\n",
    "bucket=sess.default_bucket()\n",
    "sm_client=boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_key = '{}/model/model.tar.gz'.format('inf1_compiled_model')\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model.tar.gz', model_key)\n",
    "print(\"Uploaded model to S3:\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b425d4",
   "metadata": {},
   "source": [
    "## Build and Push the container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ec8ac-df50-4cf8-82fc-44d682acaad3",
   "metadata": {},
   "source": [
    "The following shell code shows how to build the container image using docker build and push the container image to ECR using docker push.\n",
    "The Dockerfile in this example is available in the ***container*** folder.\n",
    "Here's an example of the Dockerfile:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3970025d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference-neuron:1.13.1-neuron-py310-sdk2.13.2-ubuntu20.04\n",
      "\n",
      "# Install packages \n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
      "         wget \\\n",
      "         python3-pip \\\n",
      "         python3-setuptools \\\n",
      "         nginx \\\n",
      "         ca-certificates \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "RUN ln -s /usr/bin/python3 /usr/bin/python\n",
      "RUN ln -s /usr/bin/pip3 /usr/bin/pip\n",
      "\n",
      "RUN pip --no-cache-dir install transformers flask gunicorn\n",
      "# CMD [\"/usr/local/bin/entrypoint.sh\"]\n",
      "\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "ENV PATH=\"/opt/program:${PATH}\"\n",
      "\n",
      "COPY code /opt/program\n",
      "WORKDIR /opt/program\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78b0f",
   "metadata": {},
   "source": [
    "Before running the next cell, make sure your SageMaker IAM role has access to ECR. If not, you can attache the role `AmazonEC2ContainerRegistryPowerUser` to your IAM role ARN, which allows you to upload image layers to ECR.  \n",
    "\n",
    "It takes 5 minutes to build docker images and upload image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd51acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=neuron-inference-py36\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6bbda",
   "metadata": {},
   "source": [
    "## Deploy Container and run inference based on the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65e31",
   "metadata": {},
   "source": [
    "To deploy a pretrained PyTorch model, you'll need to use the PyTorch estimator object to create a PyTorchModel object and set a different entry_point.\n",
    "\n",
    "You'll use the PyTorchModel object to deploy a PyTorchPredictor. This creates a SageMaker Endpoint -- a hosted prediction service that we can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f343d3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->Transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->Transformers) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->Transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->Transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->Transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->Transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->Transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd73b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"inf1_compiled_model/model\"\n",
    "\n",
    "# Get container name in ECR\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "algorithm_name=\"neuron-inference-py36\"\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298f2a7",
   "metadata": {},
   "source": [
    "An implementation of *model_fn* is required for inference script.\n",
    "We are going to implement our own **model_fn** and **predict_fn** for Hugging Face Bert, and use default implementations of **input_fn** and **output_fn** defined in sagemaker-pytorch-containers.\n",
    "\n",
    "In this example, the inference script is put in ***code*** folder. Run the next cell to see it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfea75b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m  \u001b[37m# to workaround a protobuf version conflict issue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mneuron\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer_init = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39;49;00m\u001b[33mbert-base-cased-finetuned-mrpc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model_file =os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mneuron_compiled_model.pt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model_neuron = torch.jit.load(model_file)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#    print(\"using {}\".format(model_file))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m (model_neuron, tokenizer_init)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(serialized_input_data)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#        print(input_data)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m input_data\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, models):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#    print('Got input Data: {}'.format(input_data))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model_bert, tokenizer = models\u001b[37m\u001b[39;49;00m\n",
      "    sequence_0 = input_data[\u001b[34m0\u001b[39;49;00m] \u001b[37m\u001b[39;49;00m\n",
      "    sequence_1 = input_data[\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    max_length=\u001b[34m128\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, max_length=max_length, padding=\u001b[33m'\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Convert example inputs to a format that is compatible with TorchScript tracing\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    example_inputs_paraphrase = paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33mtoken_type_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]  \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Verify the TorchScript works on example inputs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase_classification_logits_neuron = model_bert(*example_inputs_paraphrase)\u001b[37m\u001b[39;49;00m\n",
      "    classes = [\u001b[33m'\u001b[39;49;00m\u001b[33mnot paraphrase\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mparaphrase\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase_prediction = paraphrase_classification_logits_neuron[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].argmax().item()\u001b[37m\u001b[39;49;00m\n",
      "    out_str = \u001b[33m'\u001b[39;49;00m\u001b[33mBERT says that \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m and \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m are \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(sequence_0, sequence_1, classes[paraphrase_prediction])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m out_str\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m accept == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(prediction_output), accept\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + accept)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31a7b8",
   "metadata": {},
   "source": [
    "Path of compiled pretrained model in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61f3556e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-265645771569/inf1_compiled_model/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(pretrained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7557a5f",
   "metadata": {},
   "source": [
    "The model object is defined by using the SageMaker Python SDK's PyTorchModel and pass in the model from the estimator and the entry_point. The endpoint's entry point for inference is defined by model_fn as seen in the previous code block that prints out **inference.py**. The model_fn function will load the model and required tokenizer.\n",
    "\n",
    "Note, **image_uri** must be user's own ECR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bd99768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=pretrained_model_data,\n",
    "    role=role,\n",
    "    source_dir=\"code\",\n",
    "    framework_version=\"1.7.1\",\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=ecr_image\n",
    ")\n",
    "\n",
    "# Let SageMaker know that we've already compiled the model via neuron-cc\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67439fe7",
   "metadata": {},
   "source": [
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint.\n",
    "\n",
    "Here you will deploy the model to a single **ml.inf1.2xlarge** instance.\n",
    "It may take 6-10 min to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d771fc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!CPU times: user 10.9 s, sys: 1.22 s, total: 12.1 s\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type=\"ml.inf1.2xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab6342f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron-inference-py36-ml-inf1-2023-09-26-17-32-08-134\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059537d9",
   "metadata": {},
   "source": [
    "Since in the input_fn we declared that the incoming requests are json-encoded, we need to use a json serializer, to encode the incoming data into a json string. Also, we declared the return content type to be json string, we Need to use a json deserializer to parse the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29e82f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006ea03",
   "metadata": {},
   "source": [
    "Using a list of sentences, now SageMaker endpoint is invoked to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "325a87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT says that \"Never allow the same bug to bite you twice.\" and \"The best part of Amazon SageMaker is that it makes machine learning easy.\" are not paraphrase\n",
      "CPU times: user 14.4 ms, sys: 4.4 ms, total: 18.8 ms\n",
      "Wall time: 162 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = predictor.predict(\n",
    "    [\n",
    "        \"Never allow the same bug to bite you twice.\",\n",
    "        \"The best part of Amazon SageMaker is that it makes machine learning easy.\",\n",
    "    ]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a12410d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT says that \"The company HuggingFace is based in New York City\" and \"HuggingFace's headquarters are situated in Manhattan\" are paraphrase\n",
      "CPU times: user 3.36 ms, sys: 255 µs, total: 3.62 ms\n",
      "Wall time: 28.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = predictor.predict(\n",
    "    [\n",
    "        \"The company HuggingFace is based in New York City\",\n",
    "        \"HuggingFace's headquarters are situated in Manhattan\",\n",
    "    ]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72dfd16",
   "metadata": {},
   "source": [
    "## Benchmarking your endpoint\n",
    "\n",
    "The following cells create a load test for your endpoint. You first define some helper functions: `inference_latency` runs the endpoint request, collects cliend side latency and any errors, `random_sentence` builds random to be sent to the endpoint.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "088d0e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import boto3   \n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "038d9953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_latency(model,*inputs):\n",
    "    \"\"\"\n",
    "    infetence_time is a simple method to return the latency of a model inference.\n",
    "\n",
    "        Parameters:\n",
    "            model: torch model onbject loaded using torch.jit.load\n",
    "            inputs: model() args\n",
    "\n",
    "        Returns:\n",
    "            latency in seconds\n",
    "    \"\"\"\n",
    "    error = False\n",
    "    start = time.time()\n",
    "    try:\n",
    "        results = model(*inputs)\n",
    "    except:\n",
    "        error = True\n",
    "        results = []\n",
    "    return {'latency':time.time() - start, 'error': error, 'result': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6b200ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A sloth spies on a cat with rabies', 'My mom spies on this cool guy my gardener met yesterday']\n"
     ]
    }
   ],
   "source": [
    "def random_sentence():\n",
    "    \n",
    "    s_nouns = [\"A dude\", \"My mom\", \"The king\", \"Some guy\", \"A cat with rabies\", \"A sloth\", \"Your homie\", \"This cool guy my gardener met yesterday\", \"Superman\"]\n",
    "    p_nouns = [\"These dudes\", \"Both of my moms\", \"All the kings of the world\", \"Some guys\", \"All of a cattery's cats\", \"The multitude of sloths living under your bed\", \"Your homies\", \"Like, these, like, all these people\", \"Supermen\"]\n",
    "    s_verbs = [\"eats\", \"kicks\", \"gives\", \"treats\", \"meets with\", \"creates\", \"hacks\", \"configures\", \"spies on\", \"retards\", \"meows on\", \"flees from\", \"tries to automate\", \"explodes\"]\n",
    "    p_verbs = [\"eat\", \"kick\", \"give\", \"treat\", \"meet with\", \"create\", \"hack\", \"configure\", \"spy on\", \"retard\", \"meow on\", \"flee from\", \"try to automate\", \"explode\"]\n",
    "    infinitives = [\"to make a pie.\", \"for no apparent reason.\", \"because the sky is green.\", \"for a disease.\", \"to be able to make toast explode.\", \"to know more about archeology.\"]\n",
    "    \n",
    "    return (random.choice(s_nouns) + ' ' + random.choice(s_verbs) + ' ' + random.choice(s_nouns).lower() or random.choice(p_nouns).lower() + ' ' + random.choice(infinitives))\n",
    "\n",
    "print([random_sentence(), random_sentence()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2945dde",
   "metadata": {},
   "source": [
    "The following cell creates `number_of_clients` concurrent threads to run `number_of_runs` requests. Once completed, a `boto3` CloudWatch client will query for the server side latency metrics for comparison.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69c047e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 98.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Throughput: :97.9\n",
      "\n",
      "50th Percentile Latency:19.6 ms\n",
      "90th Percentile Latency:22.2 ms\n",
      "95th Percentile Latency:26.0 ms\n",
      "\n",
      "Errors percentage: 0.0 %\n",
      "\n",
      "Getting Cloudwatch:\n",
      "Time elapsed: 310.21425 seconds\n",
      "Using period of 360 seconds\n",
      "\n",
      "Waiting 30 seconds ...\n",
      "919.0 latency datapoints ready\n",
      "50th Percentile Latency:13.5 ms\n",
      "90th Percentile Latency:15.0 ms\n",
      "95th Percentile Latency:15.8 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining Auxiliary variables\n",
    "number_of_clients = 2\n",
    "number_of_runs = 1000\n",
    "t = tqdm(range(number_of_runs),position=0, leave=True)\n",
    "\n",
    "# Starting parallel clients\n",
    "cw_start = datetime.datetime.utcnow()\n",
    "\n",
    "results = Parallel(n_jobs=number_of_clients,prefer=\"threads\")(delayed(inference_latency)(predictor.predict,[random_sentence(), random_sentence()]) for mod in t)\n",
    "avg_throughput = t.total/t.format_dict['elapsed']\n",
    "\n",
    "cw_end = datetime.datetime.utcnow() \n",
    "\n",
    "# Computing metrics and print\n",
    "latencies = [res['latency'] for res in results]\n",
    "errors = [res['error'] for res in results]\n",
    "error_p = sum(errors)/len(errors) *100\n",
    "p50 = np.quantile(latencies[-1000:],0.50) * 1000\n",
    "p90 = np.quantile(latencies[-1000:],0.95) * 1000\n",
    "p95 = np.quantile(latencies[-1000:],0.99) * 1000\n",
    "\n",
    "print(f'Avg Throughput: :{avg_throughput:.1f}\\n')\n",
    "print(f'50th Percentile Latency:{p50:.1f} ms')\n",
    "print(f'90th Percentile Latency:{p90:.1f} ms')\n",
    "print(f'95th Percentile Latency:{p95:.1f} ms\\n')\n",
    "print(f'Errors percentage: {error_p:.1f} %\\n')\n",
    "\n",
    "# Querying CloudWatch\n",
    "print('Getting Cloudwatch:')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "statistics=['SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "extended=['p50', 'p90', 'p95', 'p100']\n",
    "\n",
    "# Give 5 minute buffer to end\n",
    "cw_end += datetime.timedelta(minutes=5)\n",
    "\n",
    "# Period must be 1, 5, 10, 30, or multiple of 60\n",
    "# Calculate closest multiple of 60 to the total elapsed time\n",
    "factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "period = factor * 60\n",
    "print('Time elapsed: {} seconds'.format((cw_end - cw_start).total_seconds()))\n",
    "print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "cloudwatch_ready = False\n",
    "# Keep polling CloudWatch metrics until datapoints are available\n",
    "while not cloudwatch_ready:\n",
    "  time.sleep(30)\n",
    "  print('Waiting 30 seconds ...')\n",
    "  # Must use default units of microseconds\n",
    "  model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='ModelLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': predictor.endpoint_name},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  # Should be 1000\n",
    "  if len(model_latency_metrics['Datapoints']) > 0:\n",
    "    print('{} latency datapoints ready'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "    side_avg = model_latency_metrics['Datapoints'][0]['Average'] / number_of_runs\n",
    "    side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / number_of_runs\n",
    "    side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / number_of_runs\n",
    "    side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / number_of_runs\n",
    "    side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / number_of_runs\n",
    "    \n",
    "    print(f'50th Percentile Latency:{side_p50:.1f} ms')\n",
    "    print(f'90th Percentile Latency:{side_p90:.1f} ms')\n",
    "    print(f'95th Percentile Latency:{side_p95:.1f} ms\\n')\n",
    "\n",
    "    cloudwatch_ready = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035e681",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Endpoints should be deleted when no longer in use, to avoid costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1284ef3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af53873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
